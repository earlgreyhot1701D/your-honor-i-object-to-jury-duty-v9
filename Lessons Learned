# ğŸ“š Lessons Learned: Jury Eligibility Chatbot (v9)

## âœ… What Went Well

- Successfully implemented Retrieval-Augmented Generation (RAG) using Claude on AWS Bedrock
- Streamlit provided a fast, clean demo UI without front-end overhead
- Fallback safety message prevented hallucinations
- Project used only public legal text â€” no confidential or sensitive data
- Got a working proof-of-concept running in less than 10 versions
- Learned how to cite legal rules while remaining neutral and accessible

## ğŸ› ï¸ Challenges Faced

- FAISS index and Bedrock integration required virtual environment setup
- PowerShell permissions had to be modified manually
- LangChain import errors due to deprecations (resolved with langchain_community)
- Unicode encoding issues with scraped text (resolved by enforcing UTF-8)
- Edge cases like â€œIâ€™m not a residentâ€ didnâ€™t match well without better semantic parsing

## ğŸ’¡ What I Learned About RAG

- RAG isnâ€™t just search + response â€” itâ€™s how you structure the retrieval *and* the prompt to produce relevant, non-hallucinated output
- Embedding quality and chunking strategy directly affect performance
- Plain-language summaries should be layered on top of RAG, not replace it
- Retrieval makes your chatbot explainable, traceable, and safe for high-stakes use

## ğŸ§­ What I Learned About Iteration and Guardrails

This project taught me that "done" doesn't mean "final" â€” especially in AI.
Each version uncovered edge cases or mismatches that helped shape the next release. Thatâ€™s the point of iteration: not to get it perfect, but to keep improving based on real use.

I also learned that **AI in public service needs clarity and constraints**:
- Guardrails arenâ€™t just technical â€” they protect trust and prevent confusion.
- Inference parameters (like temperature or top_p) directly influence tone, confidence, and safety.
- Sometimes the best answer is â€œI donâ€™t know, please call our officeâ€ â€” and thatâ€™s okay.

Going forward, Iâ€™ll treat v10 not as a conclusion, but as a more robust foundation for future learning and refinement.
### ğŸ“š Working with `kb_index/` â€“ The Vector Index

One important lesson was understanding how the `kb_index/` folder powers the Retrieval-Augmented Generation (RAG) process.
- **What I Learned**: The chatbot doesn't search plain text directly. Instead, the legal text is transformed into *embeddings* and stored in a FAISS index. This makes it possible for the AI to match juror questions to the right code sections using similarity search.
- **Why It Matters**: Without this index, the chatbot canâ€™t â€œlook upâ€ answers â€” and rebuilding it every time would be inefficient. Including the pre-built `kb_index/` in the repo avoids unnecessary compute and startup time.
- **Gotcha**: If the `kb_index/` folder is missing or corrupted, the chatbot will fail to launch. I added error handling and documentation to avoid confusion for future users.
- **Takeaway**: Even with simple demos, indexing and embedding logic is critical. This is where retrieval accuracy lives â€” not just in the model itself.

## ğŸ“¦ Setup & Deployment Notes

- Virtual environments prevent dependency conflicts and keep your project isolated
- `load_documents.py` is essential â€” it converts the legal code into a searchable FAISS vectorstore
- `.venv` + Streamlit = quick demo loop for non-dev audiences

## ğŸ§¹ Clean Repo Practices

Early versions of the repo included system-generated folders like `.venv/` and `_pycache_/`. I learned that these should be excluded from source control to keep the repo portable and lightweight. Instead, setup instructions are provided to recreate the virtual environment.

## ğŸ“Œ Versioning Matters

- This is version 9 â€” not perfect, but production-ready enough for a CCC AI Summer Camp demo
- Iterative releases made it easier to test, tweak, and explain progress
- Every version taught me something about how AI can serve public systems

## ğŸ”­ Future Mindset

- Focus on clarity, safety, and auditability over flashiness
- Build with guardrails now so future deployments can scale responsibly
